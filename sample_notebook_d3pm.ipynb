{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulheller/PythonRepositories/d3pm/d3pmvenv/lib/python3.10/site-packages/threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import lib.utils.bookkeeping as bookkeeping\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lib.models.models as models\n",
    "import lib.models.model_utils as model_utils\n",
    "from lib.datasets import mnist, maze, protein, synthetic\n",
    "import lib.datasets.dataset_utils as dataset_utils\n",
    "import lib.losses.losses as losses\n",
    "import lib.losses.losses_utils as losses_utils\n",
    "import lib.training.training as training\n",
    "import lib.training.training_utils as training_utils\n",
    "import lib.optimizers.optimizers as optimizers\n",
    "import lib.optimizers.optimizers_utils as optimizers_utils\n",
    "from lib.d3pm import make_diffusion\n",
    "import os\n",
    "from lib.datasets.maze import maze_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating path\n",
    "path = \"SavedModels/MNIST/\"\n",
    "date = '2024-05-28' # 2\n",
    "config_name = 'config_001.yaml' # config_001_hollowMLEProb.yaml\n",
    "model_name = 'model_1.pt'\n",
    "\n",
    "config_path = os.path.join(path, date, config_name)\n",
    "checkpoint_path = os.path.join(path, date, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-05-28 16:36:26.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.d3pm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1m[compute transition matrix]: gaussian\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in betas 1000\n",
      "from beta 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-05-28 16:38:43.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.d3pm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1m[trainsition matrix]: torch.Size([1000, 256, 256])\u001b[0m\n",
      "\u001b[32m2024-05-28 16:38:43.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.d3pm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1m[Construct transition matrices for q(x_t|x_start)]\u001b[0m\n",
      "\u001b[32m2024-05-28 16:39:02.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.d3pm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m144\u001b[0m - \u001b[1m[tilde(Q)t]: torch.Size([1000, 256, 256])\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "number of parameters:  1013024\n",
      "ema state dict function\n"
     ]
    }
   ],
   "source": [
    "# creating models\n",
    "cfg = bookkeeping.load_config(config_path)\n",
    "\n",
    "diffusion = make_diffusion(cfg.model)\n",
    "#print(cfg)\n",
    "device = torch.device(cfg.device)\n",
    "print(device)\n",
    "\n",
    "model = model_utils.create_model(cfg, device)\n",
    "print(\"number of parameters: \", sum([p.numel() for p in model.parameters()]))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), cfg.optimizer.lr)\n",
    "\n",
    "state = {\"model\": model, \"optimizer\": optimizer, \"n_iter\": 0}\n",
    "state = bookkeeping.load_state(state, checkpoint_path, device)\n",
    "state['model'].eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-05-28 16:39:03.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlib.d3pm\u001b[0m:\u001b[36mp_sample_loop\u001b[0m:\u001b[36m553\u001b[0m - \u001b[1mcpu\u001b[0m\n",
      "1000it [23:46,  1.43s/it]\n"
     ]
    }
   ],
   "source": [
    "n_samples = 4\n",
    "if cfg.data.name == 'Maze3S':\n",
    "    shape = (n_samples, 1, 15, 15)\n",
    "elif cfg.data.name == 'DiscreteMNIST':\n",
    "    shape = (n_samples, 1, 28, 28)\n",
    "elif cfg.data.name == 'SyntheticData':\n",
    "    shape = (n_samples, 32)\n",
    "else:\n",
    "    raise ValueError(\"wrong\")\n",
    "\n",
    "samples = diffusion.p_sample_loop(state['model'], shape, cfg.model.num_timesteps).cpu().numpy()\n",
    "saved_samples = samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.datasets.mnist_fid import evaluate_fid_score\n",
    "data = np.load(f'sample_path.npy')\n",
    "dataset_location = \"lib/datasets\"\n",
    "fid_values = []\n",
    "cfg.data.train = False\n",
    "dataset = dataset_utils.get_dataset(cfg, device, dataset_location)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "    batch_size=data.shape[0],\n",
    "    shuffle=cfg.data.shuffle)\n",
    "for true_data in (dataloader):\n",
    "    #print(f'mnist_hollow_{sampler_n}{step}.npy')\n",
    "    print(\"----------------------------------\")\n",
    "\n",
    "    fid = evaluate_fid_score(data, true_data.cpu().numpy(), 100)\n",
    "    print(\"FID:\", fid)\n",
    "    fid_values.append(fid)\n",
    "    break\n",
    "print(fid_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "\"'sampler'\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/PythonRepositories/d3pm/d3pmvenv/lib/python3.10/site-packages/ml_collections/config_dict/config_dict.py:903\u001b[0m, in \u001b[0;36mConfigDict.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 903\u001b[0m   field \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fields\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    904\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(field, FieldReference):\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sampler'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/PythonRepositories/d3pm/d3pmvenv/lib/python3.10/site-packages/ml_collections/config_dict/config_dict.py:827\u001b[0m, in \u001b[0;36mConfigDict.__getattr__\u001b[0;34m(self, attribute)\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 827\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mattribute\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/PythonRepositories/d3pm/d3pmvenv/lib/python3.10/site-packages/ml_collections/config_dict/config_dict.py:909\u001b[0m, in \u001b[0;36mConfigDict.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 909\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_did_you_mean_message(key, \u001b[38;5;28mstr\u001b[39m(e)))\n",
      "\u001b[0;31mKeyError\u001b[0m: \"'sampler'\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_img:\n\u001b[1;32m      3\u001b[0m     samples \u001b[38;5;241m=\u001b[39m samples\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, cfg\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mimage_size, cfg\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mimage_size)\n\u001b[0;32m----> 4\u001b[0m     saving_train_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(cfg\u001b[38;5;241m.\u001b[39msaving\u001b[38;5;241m.\u001b[39msample_plot_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mstate[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_iter\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg\u001b[38;5;241m.\u001b[39msampler\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mcfg\u001b[38;5;241m.\u001b[39msampler\u001b[38;5;241m.\u001b[39mnum_steps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m9\u001b[39m)) \n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_samples):\n",
      "File \u001b[0;32m~/PythonRepositories/d3pm/d3pmvenv/lib/python3.10/site-packages/ml_collections/config_dict/config_dict.py:829\u001b[0m, in \u001b[0;36mConfigDict.__getattr__\u001b[0;34m(self, attribute)\u001b[0m\n\u001b[1;32m    827\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[attribute]\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 829\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(e)\n",
      "\u001b[0;31mAttributeError\u001b[0m: \"'sampler'\""
     ]
    }
   ],
   "source": [
    "is_img = True\n",
    "if is_img:\n",
    "    samples = samples.reshape(-1, 1, cfg.data.image_size, cfg.data.image_size)\n",
    "    saving_train_path = os.path.join(cfg.saving.sample_plot_path, f\"{cfg.model.name}{state['n_iter']}_{cfg.sampler.name}{cfg.sampler.num_steps}.png\")\n",
    "    fig = plt.figure(figsize=(9, 9)) \n",
    "    for i in range(n_samples):\n",
    "        plt.subplot(int(np.sqrt(n_samples)), int(np.sqrt(n_samples)), 1 + i)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(np.transpose(samples[i, ...], (1,2,0)), cmap=\"gray\")\n",
    " \n",
    "    # saving_train_path\n",
    "    plt.savefig('image_samples.pdf', transparent=True)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "else:\n",
    "    bm, inv_bm = synthetic.get_binmap(cfg.model.concat_dim, cfg.data.binmode)\n",
    "    print(inv_bm)\n",
    "    samples = synthetic.bin2float(samples.astype(np.int32), inv_bm, cfg.model.concat_dim, cfg.data.int_scale)\n",
    "\n",
    " \n",
    "    saving_plot_path = os.path.join(path, f\"{cfg.model.name}{state['n_iter']}_{cfg.sampler.name}{cfg.sampler.num_steps}.png\")\n",
    "    saving_np_path = os.path.join(path, f\"samples_{cfg.model.name}{state['n_iter']}_{cfg.sampler.name}{cfg.sampler.num_steps}.npy\")\n",
    "    synthetic.plot_samples(samples, 'synthetic_samples.pdf', im_size=cfg.data.plot_size, im_fmt=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_mazes = maze_acc(saved_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.data.name = 'Maze3SComplete'\n",
    "cfg.data.batch_size = n_samples\n",
    "\n",
    "if cfg.data.name == 'Maze3SComplete':\n",
    "    limit = cfg.data.batch_size\n",
    "    cfg.data.limit = limit \n",
    "\n",
    "dataset = dataset_utils.get_dataset(cfg, device)\n",
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "    batch_size=cfg.data.batch_size,\n",
    "    shuffle=cfg.data.shuffle)\n",
    "\n",
    "for i in dataloader:\n",
    "    true_dl = i\n",
    "    c_i = maze_acc(i.cpu().numpy())\n",
    "    true_dl = true_dl.reshape(cfg.data.batch_size, -1) #.flatten()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
